# Learning Materials & Further Resources: Module 19 - Data Analytics & Quantitative Tools in Credit Risk (Beyond AI/ML)

## Key Terms Glossary (Module 19)

*   **Data Analytics (in Credit Risk):** The process of examining raw data related to credit to draw conclusions, identify patterns, quantify risks, and support decision-making.
*   **Quantitative Tools:** Mathematical, statistical, and computational methods used for analysis.
*   **PivotTable (Excel):** An interactive Excel tool that allows for rapid summarization, grouping, and analysis of large datasets.
*   **Power Query (Excel):** A data connection technology that enables you to discover, connect, combine, and refine data across a wide variety of sources for analysis.
*   **Power Pivot (Excel):** An Excel add-in used to perform powerful data analysis and create sophisticated data models.
*   **Statistical Functions (Excel):** Built-in Excel functions for performing basic statistical calculations (e.g., `AVERAGE`, `STDEV`, `CORREL`, `SLOPE`, `INTERCEPT`).
*   **Analysis ToolPak (Excel):** An Excel add-in that provides data analysis tools for financial, statistical, and engineering data analysis (e.g., regression, histograms).
*   **Python:** A versatile, high-level programming language widely used in data science, with extensive libraries for data manipulation, analysis, and visualization.
    *   **Pandas (Python Library):** A powerful open-source data analysis and manipulation tool built on top of Python. Key data structure is the DataFrame.
    *   **NumPy (Python Library):** Fundamental package for numerical computation in Python, providing support for large, multi-dimensional arrays and matrices.
    *   **Matplotlib / Seaborn (Python Libraries):** Widely used libraries for creating static, animated, and interactive visualizations in Python.
    *   **Statsmodels / Scikit-learn (Python Libraries):** Libraries offering many statistical models, including regression, classification, clustering, etc.
*   **R (Programming Language):** A free software environment and programming language primarily used for statistical computing, data analysis, and graphics.
*   **Business Intelligence (BI) Tools:** Software applications designed to retrieve, analyze, transform, and report data for business intelligence (e.g., Tableau, Microsoft Power BI, Qlik Sense).
    *   **Dashboard (BI):** A visual display of the most important information needed to achieve one or more objectives; consolidated and arranged on a single screen so the information can be monitored at a glance.
*   **Data Visualization:** The graphical representation of information and data. Uses visual elements like charts, graphs, and maps to provide an accessible way to see and understand trends, outliers, and patterns in data.
*   **Portfolio Segmentation:** Dividing a credit portfolio into distinct groups based on shared characteristics (e.g., industry, risk rating, loan size, geography) for targeted analysis and risk management.
*   **Early Warning Indicators (EWS - Data-Driven):** Metrics or patterns identified through data analysis that signal a potential future deterioration in credit quality.
*   **Probability of Default (PD) Model:** A statistical model that estimates the likelihood that a borrower will default on its debt obligations within a specific time horizon.
*   **Logistic Regression:** A statistical method for analyzing a dataset in which there are one or more independent variables that determine a binary outcome (e.g., default/no default).
*   **Credit Scoring Model:** A statistical model that uses various borrower characteristics to assign a numerical score representing their credit risk.
*   **Data Quality:** The accuracy, completeness, consistency, timeliness, and relevance of data. Critical for meaningful analysis ("Garbage In, Garbage Out").
*   **Correlation vs. Causation:** A statistical relationship between two variables does not necessarily mean that one causes the other.
*   **Overfitting (a Model):** Creating a statistical or machine learning model that describes random error or noise instead of the underlying relationship. Overfit models perform well on training data but poorly on new data.
*   **Back-testing (Models):** The process of testing a predictive model on historical data to see how accurately it would have performed.

## Recommended Reading & External Resources

**Advanced Excel for Data Analysis:**
*   "Excel Power Pivot & Power Query For Dummies" by Michael Alexander.
*   "Microsoft Excel Data Analysis and Business Modeling" by Wayne L. Winston.
*   Online tutorials from Microsoft or dedicated Excel MVP sites (e.g., Chandoo.org, ExcelJet).

**Introduction to Python/R for Data Analysis (Conceptual & Practical):**
*   **Books (Beginner Friendly):**
    *   "Python for Data Analysis" by Wes McKinney (creator of Pandas).
    *   "R for Data Science" by Hadley Wickham & Garrett Grolemund (excellent introduction to the Tidyverse in R).
    *   "Automate the Boring Stuff with Python" by Al Sweigart (good for learning Python basics with practical applications).
*   **Online Courses:**
    *   DataCamp, Coursera, edX, Codecademy offer numerous introductory courses on Python and R for data analysis.
*   **Websites:**
    *   Real Python ([https://realpython.com/](https://realpython.com/)) for Python tutorials.
    *   RStudio's official website ([https://www.rstudio.com/](https://www.rstudio.com/)) and R Bloggers ([https://www.r-bloggers.com/](https://www.r-bloggers.com/)) for R resources.

**Data Visualization:**
*   **Books:**
    *   "The Visual Display of Quantitative Information" by Edward R. Tufte (A classic on principles of data graphics).
    *   "Storytelling with Data: A Data Visualization Guide for Business Professionals" by Cole Nussbaumer Knaflic.
    *   "Good Charts: The HBR Guide to Making Smarter, More Persuasive Data Visualizations" by Scott Berinato.
*   **Websites/Blogs:**
    *   FlowingData ([https://flowingdata.com/](https://flowingdata.com/)) by Nathan Yau.
    *   Blogs by Tableau, Power BI, and other visualization tool vendors often have good tips.

**Quantitative Credit Risk Modeling (More Advanced, for context):**
*   "Credit Risk Modeling: Theory and Applications" by David Lando.
*   "Active Credit Portfolio Management in Practice" by Jeffrey R. Bohn and Roger M. Stein.

## Conceptual Tools & Frameworks (Beyond this Module's Content)

*   **CRISP-DM (Cross-Industry Standard Process for Data Mining):** A widely used open standard process model that describes common approaches used by data mining experts. It provides a structured approach to data analytics projects.
    *   Phases: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment.
*   **Data Audit Framework:** A checklist or process for assessing the quality, completeness, and reliability of a dataset before using it for analysis or modeling.
*   **Model Validation Checklist (for simpler statistical models):**
    *   Conceptual Soundness: Does the model make sense from a business/credit perspective?
    *   Data Quality: Is the input data accurate and appropriate?
    *   Statistical Performance: Goodness-of-fit, predictive accuracy (e.g., on out-of-time samples).
    *   Stability: Does the model perform consistently over time?
    *   Documentation: Is the model methodology, assumptions, and limitations clearly documented?
*   **Portfolio Risk Dashboard Outline:**
    *   Key sections for a credit portfolio dashboard:
        *   Overall Exposure & Growth.
        *   Concentration Analysis (Industry, Geography, Single Name).
        *   Risk Rating Distribution & Migration.
        *   Delinquency & Non-Performing Loan Trends.
        *   Covenant Breach Summary.
        *   Early Warning Indicator Summary.
        *   Stress Test Impact Highlights.

*(Note: While this module provides an overview, proficiency in specific tools like Python or R requires dedicated learning and practice. The focus here is on understanding their potential and how they fit into the credit analyst's toolkit.)*

---
This document should be considered a supplement to the main Module 19 content.
