{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Prompt Engineering for Credit Analysts\n",
    "\n",
    "Welcome to this interactive notebook! The goal of this session is to introduce you to the fundamental principles of **prompt engineering**â€”the art of crafting effective inputs for Large Language Models (LLMs) to get the most accurate, relevant, and useful outputs for your work as a credit analyst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries. We'll be using `ipywidgets` to create interactive elements like text boxes and buttons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- LLM Simulation ---\n",
    "# In a real environment, this would be a call to an actual LLM API.\n",
    "# For this educational notebook, we'll simulate the LLM's response\n",
    "# to demonstrate the principles of prompt engineering.\n",
    "\n",
    "def ask_llm(prompt):\n",
    "    \"\"\"Simulates a call to a Large Language Model.\"\"\"\n",
    "    prompt_lower = prompt.lower()\n",
    "    \n",
    "    # Rule-based responses for demonstration\n",
    "    if 'credit analyst' in prompt_lower and 'key risks' in prompt_lower:\n",
    "        return \"**Response:** Based on the provided financial statements, the key risks are: 1) High leverage with a Debt-to-EBITDA ratio of 5.5x, 2) Declining margins in the core business segment, and 3) Significant customer concentration with 40% of revenue from a single client.\"\n",
    "    elif 'summarize' in prompt_lower and 'report' in prompt_lower:\n",
    "        return \"**Response:** The report discusses the company's financial performance.\"\n",
    "    elif 'tree of thought' in prompt_lower:\n",
    "        return \"**Response:** Tree of Thoughts is an advanced technique. This notebook covers the foundations. Please see the next notebook for more on this.\"\n",
    "    else:\n",
    "        return \"**Response:** The model's response is generic because the prompt was not specific enough. Please try again with more context or a clearer role.\"\n",
    "\n",
    "print(\"Setup complete. The 'ask_llm' function is now available for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Core Principles of Prompting\n",
    "\n",
    "Effective prompting boils down to a few key principles. We'll explore them one by one with interactive examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 1: Clarity and Specificity\n",
    "\n",
    "Vague prompts lead to vague answers. The more specific your request, the better the result.\n",
    "\n",
    "**Bad Prompt:** `Summarize the report.`\n",
    "**Good Prompt:** `Summarize the key findings of the attached credit report, focusing on the company's liquidity position.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input = widgets.Textarea(\n",
    "    value='Summarize the report.',\n",
    "    placeholder='Type your prompt here',\n",
    "    description='Prompt:',\n",
    "    layout={'width': '100%', 'height': '80px'}\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(description=\"Ask LLM\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_submit_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        response = ask_llm(prompt_input.value)\n",
    "        display(Markdown(response))\n",
    "\n",
    "submit_button.on_click(on_submit_clicked)\n",
    "\n",
    "display(prompt_input, submit_button, output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 2: Provide Context\n",
    "\n",
    "The LLM doesn't know what you know. Provide the necessary context for the task.\n",
    "\n",
    "**Bad Prompt:** `Is the company's debt level appropriate?`\n",
    "**Good Prompt:** `The company operates in the cyclical manufacturing industry where the average Debt-to-EBITDA ratio is 3.0x. The company's current Debt-to-EBITDA ratio is 5.5x. Is the company's debt level appropriate?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle 3: Use Role-Playing\n",
    "\n",
    "Assigning a role to the LLM helps it adopt the right perspective and tone.\n",
    "\n",
    "**Bad Prompt:** `What are the risks?`\n",
    "**Good Prompt:** `You are a skeptical credit analyst. What are the key risks of this investment from a lender's perspective?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_input_2 = widgets.Textarea(\n",
    "    value='You are a credit analyst. Summarize the key risks in the report.',\n",
    "    placeholder='Type your prompt here',\n",
    "    description='Prompt:',\n",
    "    layout={'width': '100%', 'height': '80px'}\n",
    ")\n",
    "\n",
    "submit_button_2 = widgets.Button(description=\"Ask LLM\")\n",
    "output_area_2 = widgets.Output()\n",
    "\n",
    "def on_submit_clicked_2(b):\n",
    "    with output_area_2:\n",
    "        output_area_2.clear_output()\n",
    "        response = ask_llm(prompt_input_2.value)\n",
    "        display(Markdown(response))\n",
    "\n",
    "submit_button_2.on_click(on_submit_clicked_2)\n",
    "\n",
    "display(prompt_input_2, submit_button_2, output_area_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "You've now learned the foundational principles of prompt engineering. By writing clear, specific prompts with context and assigning a role to the AI, you can significantly improve the quality of the responses you receive.\n",
    "\n",
    "In the next notebook, we will explore advanced techniques like Chain-of-Thought and Tree of Thoughts to tackle more complex analytical tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
